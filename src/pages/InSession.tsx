// src/features/InSession.tsx
import React, { useState, useEffect, useRef } from "react";
import axios from "axios";
import { useLocation, useNavigate } from "react-router-dom";
import Avatar3D from "../components/Avatar3D";
import Transcript from "../components/Transcript";
import DrawableMathNotebook from "../components/DrawableMathNotebook";
import LessonButtons from "../components/LessonButtons";
import RealTimeRecorder from "../components/RealTimeRecorder";
import AudioUnlocker from "../components/AudioUnlocker";
import { startLesson } from "../services/lessons_api";
import { useUser } from "../context/UserContext";
import "./InSession.css";
import TopMenuBar from "../features/TopMenuBar";

const DIRECT_MODEL_URL =
  "https://threejs.org/examples/models/gltf/RobotExpressive/RobotExpressive.glb";
const socketServerUrl = process.env.SERVER_API_URL || "http://localhost:4000";

type LocationState = {
  state: {
    topic: { question: string; subject: string };
    lessonId?: string;
  };
};

const InSession: React.FC = () => {
  const { user , setUser } = useUser();
  const navigate = useNavigate();
  const { topic, lessonId: incomingId } = (useLocation() as LocationState)
    .state;

  const [lessonId, setLessonId] = useState<string>(incomingId || "");
  const [hasStarted, setHasStarted] = useState<boolean>(!!incomingId);
  const [isFinished, setIsFinished] = useState<boolean>(false);
  const [finalMessege, setFinalMessage] = useState<string>("");
  const [userTranscript, setUserTranscript] = useState<string>("");
  const [aiTranscript, setAiTranscript] = useState<string>("");
  const [processing, setProcessing] = useState<boolean>(false);
  const [isSpeaking, setIsSpeaking] = useState<boolean>(false);
  const [status, setStatus] = useState<string>(
    '×œ×—×¥ "×”×ª×—×œ ×©×™×—×”" ×›×“×™ ×œ×¤×ª×•×— ××ª ×”×©×™×—×”'
  );
  const [listening, setListening] = useState<boolean>(false);
  const [mathCount, setMathCount] = useState<number>(0);

  const audioRef = useRef<HTMLAudioElement | null>(null);
  const silenceTimerRef = useRef<NodeJS.Timeout | null>(null);
  const [isMuted, setIsMuted] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [speechRate, setSpeechRate] = useState(1);
  const [micMuted, setMicMuted] = useState(true);
  const isSpeakingRef = useRef(false);

  const toggleMicMute = () => {
    setMicMuted((prev) => !prev);
  };

  useEffect(() => {
    // Start listening only when unmuted AND not currently speaking
    if (!micMuted && !isSpeakingRef.current) {
      setListening(true);
    } else {
      setListening(false);
    }
  }, [micMuted]);

  useEffect(() => {
    if (audioRef.current) {
      audioRef.current.playbackRate = speechRate;
    }
  }, [speechRate]);
  const replayAudio = () => {
    if (audioRef.current) {
      audioRef.current.currentTime = 0;
      audioRef.current.play();
      setIsPaused(false);
      setIsSpeaking(true);
    }
  };

  const togglePause = () => {
    const audio = audioRef.current;
    if (!audio) return;

    if (audio.ended) return;

    if (audio.paused) {
      audio.play();
      setIsPaused(false);
    } else {
      audio.pause();
      setIsPaused(true);
    }
  };

  const toggleMute = () => {
    const newMuted = !isMuted;
    setIsMuted(newMuted);
    if (audioRef.current) {
      audioRef.current.muted = newMuted;
    }
  };
  useEffect(() => {
    if (incomingId) {
      setHasStarted(true);
      setListening(false);
      setStatus("××§×©×™×‘...");
    }
  }, [incomingId]);

  useEffect(() => {
    if (!hasStarted || processing || !userTranscript.trim()) return;
    if (silenceTimerRef.current) clearTimeout(silenceTimerRef.current);
    silenceTimerRef.current = setTimeout(() => {
      setListening(false);
      processTranscript(userTranscript);
    }, 2500);
    return () => {
      if (silenceTimerRef.current) clearTimeout(silenceTimerRef.current);
    };
  }, [userTranscript, processing, hasStarted]);

  const processTranscript = async (input: string) => {
    if (isSpeakingRef.current) {
      console.log("Skipping input because chat is still speaking.");
      return;
    }
    try {
      setProcessing(true);
      setStatus("××¢×‘×“ ××ª ×”×‘×§×©×” ×©×œ×š...");
      setUserTranscript("");

      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current.currentTime = 0;
      }

      // Corrected endpoint: removed "/api" prefix
      const chatResp = await axios.post(
        `${socketServerUrl}/lessons/${lessonId}/chat`,
        { question: input },
        { headers: { Authorization: `jwt ${user?.accessToken}` } }
      );

      const {
        answer: aiText,
        mathQuestionsCount,
        done,
        message,
      } = chatResp.data as {
        answer?: string;
        mathQuestionsCount?: number;
        done?: boolean;
        message?: string;
      };

      if (done) {
        setIsFinished(true);
        setFinalMessage(message || "×”×©×™×¢×•×¨ ×”×¡×ª×™×™×");
        setStatus(message!);
        setTimeout(() => handleEndLesson(), 1200);
        return;
      }

      if (isFinished) {
        return (
          <div className="end-screen container mx-auto p-6 text-center">
            <h1 className="text-4xl font-bold mb-4">ğŸ‰ ×›×œ ×”×›×‘×•×“! ğŸ‰</h1>
            <p className="text-lg mb-6">{finalMessege}</p>
            <p className="mb-6">×¢× ×™×ª ×¢×œ ×›×œ 15 ×”×©××œ×•×ª ×‘×”×¦×œ×—×”.</p>
            <div className="space-x-4">
              <button
                className="px-4 py-2 rounded shadow hover:shadow-lg transition"
                onClick={() => navigate("/home")}
              >
                ×—×–×•×¨ ×œ×“×£ ×”×‘×™×ª
              </button>
              <button
                className="px-4 py-2 rounded shadow hover:shadow-lg transition"
                onClick={resetConversation}
              >
                × ×¡×” ×©×•×‘
              </button>
            </div>
          </div>
        );
      }

      setAiTranscript(aiText!);
      if (typeof mathQuestionsCount === "number") {
        setMathCount(mathQuestionsCount);
      }

      setStatus("×××™×¨ ×˜×§×¡×˜ ×œ×“×™×‘×•×¨...");
      const ttsResp = await axios.post(
        `${socketServerUrl}/api/tts`,
        { text: aiText, lang: "he-IL" },
        { responseType: "arraybuffer" }
      );
      const audioBlob = new Blob([ttsResp.data], { type: "audio/mp3" });
      const audioUrl = URL.createObjectURL(audioBlob);
      const audio = new Audio(audioUrl);
      audio.muted = isMuted;
      audio.playbackRate = speechRate;
      audioRef.current = audio;

      setStatus("××“×‘×¨...");
      setIsSpeaking(true);
      isSpeakingRef.current = true;
      await audio.play();
      audio.onended = () => {
        isSpeakingRef.current = false;
        setIsSpeaking(false);
        setStatus("××§×©×™×‘...");
        setListening(true);
        setProcessing(false);
      };
    } catch (err) {
      console.error("Error processing transcript:", err);
      setStatus("×©×’×™××” ×‘×¢×™×‘×•×“ ×”×˜×§×¡×˜");
      setProcessing(false);
    }
  };

  const handleStartConversation = async () => {
    if (!user) return;
    try {
      setStatus("×× ×¡×” ×œ×”×ª×—×™×œ...");
      const lesson = await startLesson(
        user,
        topic.subject,
        lessonId || undefined
      );
           // â¡ï¸ ××—×¨×™ ×”×ª×—×œ×ª ×”×©×™×¢×•×¨ â€“ ×¢×“×›×•×Ÿ ×”Ö¾subjectsList ×‘Ö¾UserContext
     setUser(prev => {
         if (!prev) return prev;
         return {
           ...prev,
           subjectsList: prev.subjectsList?.filter(s => s !== topic.subject),
         };
       });
       console.log("Updated user in context:", user);
      setLessonId(lesson._id);
      setMathCount(lesson.mathQuestionsCount || 0);
      setHasStarted(true);
      setListening(true);
      setStatus("××§×©×™×‘...");
      const AudioContext =
        window.AudioContext || (window as any).webkitAudioContext;
      const audioCtx = new AudioContext();
      if (audioCtx.state === "suspended") await audioCtx.resume();
    } catch (err) {
      console.error("Error starting conversation:", err);
      setStatus("×©×’×™××” ×‘×”×ª×—×œ×ª ×”×©×™×—×”");
    }
  };

  const handleEndLesson = async () => {
    if (user && lessonId) {
      try {
        // await endLesson(user, lessonId);
      } catch (err) {
        console.error("Error ending lesson:", err);
      }
    }
    setStatus("×”×©×™×¢×•×¨ ×”×¡×ª×™×™×");
    audioRef.current?.pause();
    navigate("/home");
  };

  const resetConversation = () => {
    setUserTranscript("");
    setAiTranscript("");
    setIsSpeaking(false);
    setListening(true);
    setProcessing(false);
    setStatus("××•×›×Ÿ");
  };

  if (!hasStarted) {
    return (
      <div className="in-session-page">
        <AudioUnlocker />
        <div className="session-container">
          <div className="start-container">
            <div className="start-title">
              ?×”×× ××ª/×” ××•×›×Ÿ/××•×›× ×” ×œ×”×ª×—×™×œ ××ª ×”×©×™×¢×•×¨
            </div>
            <button onClick={handleStartConversation} className="start-button">
              ×”×ª×—×œ ×©×™×—×”
            </button>
          </div>
        </div>
      </div>
    );
  }

  return (
    <>
      <TopMenuBar onEndLesson={handleEndLesson} />

      <div className="in-session-page">
        <AudioUnlocker />
        <div className="session-container">
          <div className="chat-area">
            <Avatar3D
              modelSrc={DIRECT_MODEL_URL}
              isSpeaking={isSpeaking}
              speech={aiTranscript || userTranscript}
              fallbackImageSrc="https://via.placeholder.com/300/f0f0f0/333?text=Avatar"
              audioRef={audioRef}
              toggleMute={toggleMute}
              isMuted={isMuted}
              isPaused={isPaused}
              togglePause={togglePause}
              replayAudio={replayAudio}
              speechRate={speechRate}
              setSpeechRate={setSpeechRate}
              micMuted={micMuted}
              toggleMicMute={toggleMicMute}
              listening={listening}
              setListening={setListening}
            />
            <div className="status-display">
              <p>×¡×˜×˜×•×¡: {status}</p>
            </div>
            {topic.subject.toLowerCase() === "math" && (
              <div className="math-progress">
                ×©××œ×•×ª ××ª××˜×™×§×”: {mathCount} / 15
              </div>
            )}
            <Transcript
              text={aiTranscript || userTranscript}
              isLoading={processing}
            />

            {listening && (
              <RealTimeRecorder
                onTranscript={setUserTranscript}
                micMuted={micMuted}
              />
            )}
          </div>
          <div className="lesson-buttons-area">
            <LessonButtons
              onActionPerformed={(action) => {
                if (action === "end-lesson") handleEndLesson();
              }}
            />
          </div>

          <div className="helper-buttons">
            <button onClick={resetConversation} className="reset-button">
              ××ª×—×œ ×©×™×—×”
            </button>
          </div>
          <DrawableMathNotebook
            isSpeaking={isSpeaking}
            question={topic.question}
            onRecognize={processTranscript}
          />
        </div>
      </div>
    </>
  );
};

export default InSession;
